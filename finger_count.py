# -*- coding: utf-8 -*-
"""finger count.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17PiNeSG5XKEmEzfoVISZhfW7C_u8Yw7f
"""

!pip install mediapipe

!unzip /content/drive/MyDrive/cut-20240827T121655Z-001.zip

import cv2
import numpy as np
import mediapipe
import os

drawingModule = mediapipe.solutions.drawing_utils
handsModule = mediapipe.solutions.hands
hands = handsModule.Hands()

main_loc=os.listdir(os.path.join('/content/cut'))
main_loc.sort()
data=np.array(main_loc)
one=data[:4]
two=data[4:8]
three=data[8:12]
four=data[12:16]
five=data[16:20]

def video_to_frames(main_loc, output_loc):
  for i in main_loc:
    input_loc=i
    capture = cv2.VideoCapture('/content/cut/'+input_loc)
    frameNr = 0
    while (True):
      success, frame = capture.read()
      if success:
        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        if results.multi_hand_landmarks !=None:
          for handLandmarks in results.multi_hand_landmarks:
            drawingModule.draw_landmarks(frame, handLandmarks, handsModule.HAND_CONNECTIONS)
        cv2.imwrite(os.path.join(output_loc , f'image{frameNr}.jpg'), frame)
        cv2.waitKey(0)
      else:
        break
      frameNr = frameNr+1
    capture.release()

video_to_frames(one,'/content/data/one')
video_to_frames(two,'/content/data/two')
video_to_frames(three,'/content/data/three')
video_to_frames(four,'/content/data/four')
video_to_frames(five,'/content/data/five')

def read_frames(folder_path):
    x = []
    y = []
    for filename in os.listdir(folder_path):
      for image_path in os.listdir(os.path.join(folder_path,filename)):
        if image_path.endswith('.jpg'):
            frame = cv2.imread(os.path.join(folder_path,filename,image_path))
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame = cv2.resize(frame, (224, 224))
            x.append(frame)
            y.append(filename)
    return x,y

X,Y=read_frames('/content/data')

X=np.array(X)
Y=np.array(Y)
print(X.shape)
print(Y.shape)

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
Y=le.fit_transform(Y)
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)

print(le.classes_)

import keras
import tensorflow as tf
from keras.models import Sequential # import sequential class

from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout # import needed layers

from tensorflow.keras.utils import to_categorical
Y_train = to_categorical(Y_train, num_classes=5)
Y_test = to_categorical(Y_test, num_classes=5)

model = Sequential() # create a model with sequential class

# Layers are added sequentialy
# 1st layer: convolution has 16 filters ( 3 x 3 pixels inside).
# The power is coming from activation function. Relu is replacing null values.
model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(224,224,3)))
# 2nd layer - choose maximum value after the relu activation (2 x 2)
model.add(MaxPooling2D())
# 3rd layer, output is only 1 value, use 32 filters
model.add(Conv2D(32, (3,3), 1, activation='relu'))
# 4th layer
model.add(MaxPooling2D())
model.add(Conv2D(16, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())
# flatten the data again down
model.add(Flatten())
# convolution has 2 Dense layers
model.add(Dense(256, activation='relu')) # output is 256 values
# The final sigmoid layer, close to 0 are mountains, close to 1 is the city
# Sigmoid activation is non-linear, continuously differentiable, monotonic, and has a fixed output range. Main advantage is simple and good for classifier.
# Sigmoid activation gives rise to a problem of “vanishing gradients” because Its output isn’t zero centered. Sigmoid activation is computationaly more expensive.
model.add(Dense(5, activation='softmax')) # single dense layer is the final layer, converts values between 0 and 1


model.compile('adam', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])

model.summary()
# if the layer is not trainable, there is 0 in Param column
# total params stands for the total size of our model

hist = model.fit(X_train,Y_train, epochs=11, validation_data=(X_test,Y_test))

from google.colab.patches import cv2_imshow

cv2_imshow(X_test[10])
pred=model.predict(X_test[10].reshape(1,224,224,3))
pred=np.argmax(pred)
print(pred)
pred=le.classes_[pred]
print(pred)
cv2.putText(X_test[10],pred,(10,30),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)
cv2_imshow(X_test[10])

import cv2
import numpy as np
import mediapipe
import os
from google.colab.patches import cv2_imshow

test_data=[]
test_data.append(X_test[6])
test_data.append(X_test[7])
test_data.append(X_test[0])
test_data.append(X_test[2])
test_data.append(X_test[1])
test_data=np.array(test_data)
pred=model.predict(test_data.reshape(5,224,224,3))
label=[]
for i in range(len(pred)):
    pred=np.argmax(i)
    pred=le.inverse_transform([i])
    label.append(pred)
label=np.array(label)
import matplotlib.pyplot as plt
import cv2
plt.figure(figsize=(20,10))
for i in range(5):
    ax=plt.subplot(1,5,i+1)
    cv2.putText(test_data[i],label[i][0],(10,30),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)
    plt.imshow(test_data[i])
    plt.axis('off')